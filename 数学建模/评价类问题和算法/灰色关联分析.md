**注意一下这节内容中清风的Excel使用**，重点看看他是怎么固定某个值不动的($B$10, $B10, B$10有什么不同？)，还有AVERAGE函数，ABS函数用法，如何保留有效数字

用于系统（社会系统、经济系统、农业系统、生态系统、教育系统）分析，寻找主要/次要因素、重要/阻碍因素

比较小众，美赛慎用，能用传统回归的话先优先考虑传统回归

>数理统计中的回归分析、方差分析、主成分分析等都是用来进行系统分析的方法。这些方法都有下述不足之处:
   (1) 要求有大量数据，数据量少就难以找出统计规律;
   (2) 要求样本服从某个典型的概率分布，要求各因素数据与系统特征数据之间呈线性关系且各因素之间彼此无关,这种要求往往难以满足;
   (3) 计算量大，一般要靠计算机帮助;
   (4) 可能出现量化结果与定性分结果不符的现象，导致系统的关系和规律遭到歪曲和颠倒。

**基本思想**：
根据序列曲线几何形状的相似程度来判断其联系是否紧密。
曲线越接近，相应序列之间的关联度就越大，反之越小。

### 应用&例子
#### 01 进行系统分析
![[微信截图_20230707154126.png]]
![[微信截图_20230707154203.png]]

##### Step1: 画统计图
1. 第二产业增幅较明显
2. 四个变量均上升
3. 二产和三产在后三年差距增大

##### Step2: 确定分析序列
**1. 母序列（母指标、参考数列）：** 能反映系统行为特征的数据序列，类似于因变量 Y，此处记为$X_0$

**2. 子序列（子指标、比较数列）：** 影响系统行为的因素组成的数据序列，类似于自变量X，此处记为($X_1,X_2,...X_n)

本例中，国内生产总值就是母序列($X_0$)，第一、第二、第三产业即为子序列($X_1,X_2,X_3$)

##### Step3: 对变量进行预处理（两个目的：去量纲、缩小变量范围简化计算）
预处理方法：先求出每个指标的均值，再用该指标中的每个元素都除以该均值（不同于归一化)
![[微信截图_20230707155015.png]]

##### Step4: 计算子序列中各个指标与母序列的关联系数（灰色系数）
$$X_0 = (x_0(1), x_0(2), ... , x_0(n))^T \quad 母序列$$
$$X_1 = (x_1(1),x_1(2), ... , x_1(n))^T \quad 子序列 $$
$$X_2 = (x_2(1), x_2(2), ... , x_2(n))^T \quad 子序列 $$
$$ ...$$
$$X_m = (x_m(1), x_m(2), ... , x_m(n))^T \quad 子序列$$
 设 $两级最小差：a = min(min|x_0(k)-x_i(k)|),\ 两级最大差：b = max(max|x_0(k)-x_i(k)|)$
![[微信截图_20230707160945.png]]

定义：$$y/gamma (x_0(k), x_i(k)) = \frac{a + \rho b}{|x_0(k) - x_i(k)| + \rho b} \quad \rho: 分辨系数(一般取0,5)$$
其中，$i = 1,2, ..., m; \quad k=1,2,...n$

##### Step5: 计算灰色关联度
定义：$$y(X_0, X_i) = \frac{1}{n} \sum_{k=1}^n y(x_0(k), x_i(k))$$为 $X_0$ 和 $X_i$ 的灰色关联度（求均值）

eg. $y(X_0, X_1)=0.5084, \ y(X_0, X_2)=0.6243, \ y(X_0, X_3)=0.7573$

##### Step 6: 比较子序列与母序列关联度
通过比较子序列与母序列关联度，其中某个子序列灰色关联度最大说明母序列受到该子序列影响最大

eg. 该地区在2000年至2005年的国内生产总值受到第三产业的影响最大（其灰色关联度最大）

#### 注意
1. 什么时候用标准化回归，什么时候用灰色关联分析？
	当样本个数n较大时，一般使用标准化回归；
	当样本个数n较少时，可以考虑灰色关联分析

2. 如果母序列中有多个指标，应该怎么分析？
	例如：$Y_1, Y_2$ 是母序列，$X_1, X_2, ... , X_n$ 是子序列
	那么首先计算$Y_1$ 和 $X_1, X_2,..., X_m$ 的灰色关联度进行分析，再计算 $Y_2$ 和 $X_1, X_2,...,X_m$ 的灰色关联度进行分析

### 代码实现
```python
import numpy as np  
from numpy import loadtxt  
# 使用NumPy导入csv数据，此处以清风的gdp数据为模板  
  
# 注意data1要和py文件放在一个文件夹里面才能使用相对路径  
filename = 'data1.csv'  
  
# 有时候要注意这里的encording形式  
with open(filename, 'rt') as raw_data:  
   data = loadtxt(raw_data, delimiter=',')  
   # print(data.shape)  
   # print(data)  
   # 预处理  
   # 求均值  
   Mean = np.mean(data, axis=0)  
   # 除以均值  
   data = data / np.tile(Mean, (len(data), 1))  
   # 获得子、母序列  
   Y = data[:, 0]  
   X = np.delete(data, 0, 1)  
  
   # 计算两极最小差、两极最大差  
   Y = np.tile(Y, (len(X[0]), 1))  
   Y = np.transpose(Y)  
   abs_Y_X = np.abs(X - Y)  
   a = np.min(np.min(abs_Y_X))  
   b = np.max(np.max(abs_Y_X))  
  
   # 计算灰色系数  
   rho = 0.5  
   gamma = (a + rho * b) / (abs_Y_X + rho * b)  
  
   # 计算灰色关联度  
   grey_connection = np.mean(gamma, axis=0)  
  
   print(grey_connection)
```

### 实际应用
![[微信截图_20230707223823.png]]

#### step1: 正向化
![[TOPSIS法（优劣解距离法）#Step1 将原始矩阵正向化]]
#### step2: 预处理得到矩阵$Z_{n \times m} = (z_{ij})_{n \times m }$

#### step3: 将预处理后的矩阵每一行取出最大值构成母序列（虚构的）

#### step4: 计算各个指标与母序列的灰色关联度: $r_1, r_2,...r_m$

#### step5: 计算各个指标的权重：
$$w_1 = \frac{r_1}{r_1 + r_2 + ... + r_m}$$
$$w_2 = \frac{r_2}{r_1 + r_2 + ... + r_m}$$
$$...$$
$$w_m =\frac{r_m}{r_1 + r_2 + ... + r_m}$$

#### step6: 第 k 个评价对象的得分：
$$S_k = \sum_{i=1}^m z_{ki} * w_i, \ (k=1,2,...n)$$
#### step 7: 对得分进行归一化
$$S'_1=\frac{S_1}{S_1+S_2+...+S_n}$$
$$S'_2=\frac{S_2}{S_1+S_2+...+S_n}$$
$$ ... $$
$$S'_n=\frac{S_n}{S_1+S_2+...+S_n}$$

### 代码实现
```python
import numpy as np  
from numpy import loadtxt  
# 使用NumPy导入csv数据，此处以清风的河流监测数据为模板  
  
# 定义正向化函数：  
# 极小型->极大型  
def positivization_1(X):  
    M = np.max(X)  
    # len(X)与X.shape(0)效果一样（二维数组情况下）  
    for i in range(0, len(X)):  
        X[i] = M-X[i]  
    return X  
  
# 中间型->极大型  
def positivization_2(X, best):  
    # 一个向量与一个常数做加减乘除，相当于对向量中的每一个数进行加减乘除  
    M = np.max(np.abs(X - best))  
    for i in range(0, len(X)):  
        X[i] = 1 - np.abs(X[i] - best)/M  
    return X  
  
# 区间型->极大型  
def positivization_3(X, a, b):  
    M = max(a - np.min(X), np.max(X) - b)  
    for i in range(0, len(X)):  
        if X[i] <= a:  
            X[i] = 1 - (a-X[i])/M  
        elif X[i] >= b:  
            X[i] = 1 - (X[i]-b)/M  
        else:  
            X[i] = 1  
    return X  
  
def norm(Grade):  
    sum = 0  
    for i in range(0, len(Grade)):  
        sum = sum + Grade[i]  
    for i in range(0, len(Grade)):  
        Grade[i] = Grade[i] / sum  
    return Grade  
  
# 有时候要注意这里的encording形式  
# 注意data1要和py文件放在一个文件夹里面才能使用相对路径  
filename = 'data2.csv'  
  
with open(filename, 'rt') as raw_data:  
    data = loadtxt(raw_data, delimiter=',')  
    # print(data.shape)  
    # print(data)  
    #对矩阵正向化  
    data = data.T  
    data[1] = positivization_2(data[1], 7)  
    data[2] = positivization_1(data[2])  
    data[3] = positivization_3(data[3], 10, 20)  
    data = data.T  
  
    # 预处理  
    # 求均值  
    Mean = np.mean(data, axis=0)  
    # 除以均值  
    data = data / np.tile(Mean, (len(data), 1))  
  
    # 获得子、母序列  
    Y = np.max(data, axis = 1)  
    X = data  
  
    # 计算两极最小差、两极最大差  
    Y = np.tile(Y, (len(X[0]), 1))  
    Y = np.transpose(Y)  
    abs_Y_X = np.abs(X - Y)  
    a = np.min(np.min(abs_Y_X))  
    b = np.max(np.max(abs_Y_X))  
  
    # 计算灰色系数  
    rho = 0.5  
    gamma = (a + rho * b) / (abs_Y_X + rho * b)  
  
    # 利用灰色关联度计算权重  
    grey_connection = np.mean(gamma, axis=0)  
    weight = grey_connection / np.sum(grey_connection)  
  
    # 计算得分  
    weight = np.tile(weight, (len(X), 1))  
    grade = np.sum(X * weight, axis=1)  
  
    # 对评分归一化  
    grade_norm = norm(grade)  
    print(f'未排序得分{grade_norm}')  
  
    # 对评分进行排序并返回索引  
    Grade_norm_sorted = np.argsort(grade_norm)  
    print(f'排序得分{np.sort(grade_norm)}')  
    print(f'对应样本{Grade_norm_sorted}')
```